import pandas as pd
import time
import os
import numpy as np
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
import torch
import cProfile
from pstats import Stats

LABEL_FILE = "/scratch/am9031/CSCI-GA.3033-023/kaggleamazon/labels.txt"
TRAIN_FILE = "/scratch/am9031/CSCI-GA.3033-023/kaggleamazon/train.csv"
TEST_FILE = "/scratch/am9031/CSCI-GA.3033-023/kaggleamazon/test.csv"
PIC_DIR = "/scratch/am9031/CSCI-GA.3033-023/kaggleamazon/train-jpg"
BATCH_SIZE = 100
NUM_WORKERS = 16 
NUM_EPOCHS = 10

class PicDataset(Dataset):
    """picture dataset class."""

    def __init__(self, label_file, pic_file, root_dir):
        """
        Args:
            label_file (string): Path to the csvfile with tag-label pairings.
            pic_file (string): Path to the csv file with names and tags.
            root_dir (string): Directory with all the images.
        """
        labels = {}

        with open(label_file, 'r') as f:
            for l in f.readlines():
                tag, label = l.split(" ")
                labels[int(tag)] = label.strip('\n')

        self.labels = labels
        self.pics_frame = pd.read_csv(pic_file)
        self.root_dir = root_dir
        self.tf = transforms.Compose([
            transforms.Resize((32,32)),
            transforms.ToTensor(),
        ])
        self.total_io = 0
        self.total_pp = 0
        self.total_load = 0

    def __len__(self):
        return len(self.pics_frame)

    def io(self, idx):
        '''
        function that performs io of image data
        '''

        start = time.monotonic()
        img_name = os.path.join(self.root_dir,
                                self.pics_frame.iloc[idx, 0])+".jpg"
        img = Image.open(img_name)
        end = time.monotonic()
        self.total_io += (end - start)
        tag = self.pics_frame.iloc[idx, 1]
        label = self.labels[tag]
        sample = {'image': img, 'tag': tag, 'label':label}
        if idx == (self.__len__() - 1):
            print("TOTAL IO TIME FOR EPOCH %s" %self.total_io)
        return(sample)

    def preprocess(self, sample, idx):
        '''
        function that preforms preprocessing of image data
        '''
        start = time.monotonic()
        img = self.tf(sample['image'])
        img = img[:3,:,:]
        sample['image'] = img
        end = time.monotonic()
        self.total_pp += (end - start)
        if idx == (self.__len__() - 1):
            print("TOTAL PREPROCESS TIME FOR EPOCH %s" %self.total_pp)
        return sample

    def __getitem__(self, idx):
        '''
        __getitem__ overwritten as required by DataLoader class.  calls self.io
        and self.preprocess and then returns resulting sample
        '''

        start = time.monotonic()
        sample = self.io(idx)
        new_sample = self.preprocess(sample, idx)
        end = time.monotonic()
        self.total_load += (end - start)
        if idx == (self.__len__() - 1):
            print("TOTAL LOAD TIME FOR EPOCH %s" %self.total_load)
        return new_sample


class PicClassifier(nn.Module):
    '''
    Feed forward model.  Composed of two layers and two Relu Activation
    functions and softmax output
    '''

    def __init__(self, num_labels, batch_size):
        super(PicClassifier, self).__init__()

        self.batch_size = batch_size
        self.layer1 = nn.Linear(3072, 1024)
        self.layer2 = nn.Linear(1024, 256)
        self.layer3 = nn.Linear(256, num_labels)

    def forward(self, x):
        x = x.view(self.batch_size, 3072)
        x = F.relu(self.layer1(x))
        x = F.relu(self.layer2(x))
        x = F.softmax(self.layer3(x), dim=0)
        return x


def main():

    train_dataset = PicDataset(LABEL_FILE, TRAIN_FILE, PIC_DIR)
    test_dataset = PicDataset(LABEL_FILE, TEST_FILE, PIC_DIR)
    train_dl = DataLoader(
        train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS
    )
    test_dl = DataLoader(
        test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS
    )
    picClassifier = PicClassifier(num_labels = 17,
                                  batch_size=BATCH_SIZE).cuda() 
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(picClassifier.parameters(), lr=.01, momentum=2)

    epoch_start_time = time.monotonic() 

    start = time.monotonic()
    for epoch in range(NUM_EPOCHS):
        print("RUNNING EPOCH %s" %epoch)

        running_loss = 0.0
        for i, data in enumerate(train_dl, 0):

            inputs = Variable(data['image']).cuda()
            tags = Variable(data['tag']).cuda()

            optimizer.zero_grad()
            outputs = picClassifier(inputs)  
            loss = criterion(outputs, tags)
            loss.backward()
            optimizer.step()

            running_loss += loss.data[0]
#            if ((i % 20) == 19):
#                print('[%d, %5d] loss: %.3f' %
#                      (epoch +1, i + 1, running_loss / 20))
#                running_loss = 0.0

    end = time.monotonic()
    print("TOTAL TIME FOR ALL EPOCHS %s" %(end-start))
    print("AVG TIME FOR AN EPOCHS %s" %(float(end-start)/NUM_EPOCHS))

           
if __name__ == "__main__":
#    cProfile.run('main()', 'C7.stats')
#
#    with open('pytorch_stats.txt', 'wt') as output:
#        stats = Stats('C7.stats')
#        stats.sort_stats('cumulative', 'time')
#        stats.print_stats()
    main()






